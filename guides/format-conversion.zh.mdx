---
title: "æ ¼å¼è½¬æ¢å’Œæ™ºèƒ½è½¬å‘"
description: "äº†è§£ PipeLLM ç½‘å…³å¦‚ä½•åœ¨å¹³å°ä¹‹é—´è¿›è¡Œæ ¼å¼è½¬æ¢"
i18n: "zh"
---

# æ ¼å¼è½¬æ¢å’Œæ™ºèƒ½è½¬å‘

PipeLLM ç½‘å…³çš„æ ¸å¿ƒåŠŸèƒ½æ˜¯**åè®®è½¬æ¢**å’Œ**æ™ºèƒ½è½¬å‘**ã€‚ä½¿ç”¨å®˜æ–¹ SDKï¼ˆAnthropicã€OpenAIã€Google ç­‰ï¼‰ï¼Œæˆ‘ä»¬è‡ªåŠ¨å°†è¯·æ±‚è½¬æ¢ä¸ºä¸åŒå¹³å°çš„åè®®ï¼Œå¹¶å°†å“åº”è½¬æ¢å›æ‚¨æœŸæœ›çš„æ ¼å¼ã€‚

**æœ€å¤§ä¼˜åŠ¿**ï¼šæ— éœ€å­¦ä¹ æ–° APIï¼ä½¿ç”¨ç†Ÿæ‚‰çš„ SDKï¼Œæˆ‘ä»¬å¤„ç†æ‰€æœ‰åè®®å·®å¼‚ã€‚

## ğŸ”„ å·¥ä½œåŸç†

```
æ‚¨çš„ä»£ç ï¼ˆAnthropic SDKï¼‰
    â†“
[PipeLLM ç½‘å…³]
    â†“ ï¼ˆåè®®è½¬æ¢ï¼‰
AWS Bedrock / Google Vertex / Azure
    â†“ ï¼ˆåè®®è½¬æ¢ï¼‰
[PipeLLM ç½‘å…³]
    â†“
æ‚¨çš„ä»£ç ï¼ˆä»ç„¶æ˜¯ Anthropic æ ¼å¼ï¼‰
```

**å…³é”®ç‚¹**ï¼š
- ä½¿ç”¨åŸç”Ÿ SDKï¼ˆä¾‹å¦‚ Anthropicï¼‰
- å‘é€æ ‡å‡†åè®®è¯·æ±‚
- æˆ‘ä»¬å°†è¯·æ±‚è½¬æ¢ä¸ºç›®æ ‡å¹³å°æ ¼å¼
- ç›®æ ‡å¹³å°å¤„ç†è¯·æ±‚
- æˆ‘ä»¬å°†å“åº”è½¬æ¢å›æ‚¨çš„ SDK æ ¼å¼
- æ‚¨çš„ä»£ç æ— éœ€æ›´æ”¹

## ğŸ“Š æ”¯æŒçš„åè®®è½¬æ¢

### 1. Anthropic SDK â†” å¹³å°
ä½¿ç”¨ Anthropic å®˜æ–¹ SDKï¼Œæˆ‘ä»¬å¤„ç†åè®®è½¬æ¢ã€‚

**ç¤ºä¾‹ï¼šAnthropic SDK â†’ Bedrock**
```python
# æ‚¨çš„ä»£ç ï¼ˆæ ‡å‡† Anthropic SDKï¼‰
from anthropic import Anthropic

client = Anthropic(
    api_key="your-pipellm-key",
    base_url="https://api.pipellm.com/v1"  # æŒ‡å‘æˆ‘ä»¬çš„ç½‘å…³
)

# æ ‡å‡† Anthropic API è°ƒç”¨
response = client.messages.create(
    model="claude-3-sonnet",
    max_tokens=1000,
    messages=[{"role": "user", "content": "Hello"}]
)

print(response.content[0].text)  # ç›´æ¥ä½¿ç”¨
```

**å®é™…è½¬æ¢**ï¼š
| æ‚¨çš„ SDK | ç›®æ ‡å¹³å° | è½¬æ¢ |
|---------|---------|------|
| Anthropic SDK | AWS Bedrock | Anthropic â†’ Bedrock åè®® |
| Anthropic SDK | Google Vertex | Anthropic â†’ Vertex åè®® |
| Anthropic SDK | Azure | Anthropic â†’ Azure åè®® |
| Anthropic SDK | Anthropic å®˜æ–¹ | ç›´æ¥é€ä¼  |

**æ‚¨çš„å“åº”**ï¼š
```json
{
  "id": "msg-123",
  "content": [{"type": "text", "text": "Hello!"}],
  "model": "claude-3-sonnet",
  "role": "assistant",
  "usage": {"input_tokens": 15, "output_tokens": 25}
}
```

### 2. OpenAI SDK â†” å¹³å°
ä½¿ç”¨ OpenAI å®˜æ–¹ SDKã€‚

**ç¤ºä¾‹ï¼šOpenAI SDK â†’ Azure**
```python
# æ‚¨çš„ä»£ç ï¼ˆæ ‡å‡† OpenAI SDKï¼‰
import openai

client = openai.OpenAI(
    api_key="your-pipellm-key",
    base_url="https://api.pipellm.com/v1"  # æŒ‡å‘æˆ‘ä»¬çš„ç½‘å…³
)

# æ ‡å‡† OpenAI API è°ƒç”¨
response = client.chat.completions.create(
    model="gpt-4",
    messages=[{"role": "user", "content": "Hello"}],
    max_tokens=100
)

print(response.choices[0].message.content)  # ç›´æ¥ä½¿ç”¨
```

**å®é™…è½¬æ¢**ï¼š
| æ‚¨çš„ SDK | ç›®æ ‡å¹³å° | è½¬æ¢ |
|---------|---------|------|
| OpenAI SDK | Azure OpenAI | OpenAI â†’ Azure åè®® |
| OpenAI SDK | AWS Bedrock | OpenAI â†’ Bedrock åè®® |
| OpenAI SDK | Google Vertex | OpenAI â†’ Vertex åè®® |
| OpenAI SDK | OpenAI å®˜æ–¹ | ç›´æ¥é€ä¼  |

### 3. Google SDK â†” å¹³å°
ä½¿ç”¨ Google çš„åŸç”Ÿåº“æˆ–æ ‡å‡† Gemini APIã€‚

**ç¤ºä¾‹ï¼šGemini API â†’ Vertex AI**
```python
# æ ‡å‡† Gemini API
import requests

headers = {
    "Authorization": f"Bearer your-pipellm-key",
    "Content-Type": "application/json"
}

data = {
    "model": "gemini-pro",
    "contents": [{"role": "user", "parts": [{"text": "Hello"}]}]
}

response = requests.post(
    "https://api.pipellm.com/v1/chat/completions",
    headers=headers,
    json=data
)

result = response.json()
print(result["choices"][0]["message"]["content"])
```

**å®é™…è½¬æ¢**ï¼š
| æ‚¨çš„ SDK | ç›®æ ‡å¹³å° | è½¬æ¢ |
|---------|---------|------|
| Gemini SDK | Google Vertex | Gemini â†’ Vertex åè®® |
| Gemini SDK | AWS Bedrock | Gemini â†’ Bedrock åè®® |
| Gemini SDK | å…¶ä»–å¹³å° | Gemini â†’ å¹³å°åè®® |

## ğŸ¯ æ™ºèƒ½è½¬å‘ç­–ç•¥

### 1. è‡ªåŠ¨è´Ÿè½½å‡è¡¡
åŸºäºä»¥ä¸‹å› ç´ é€‰æ‹©æœ€ä½³æä¾›å•†ï¼š
- **å¯ç”¨æ€§**ï¼šå®æ—¶å¥åº·ç›‘æ§
- **å»¶è¿Ÿ**ï¼šé€‰æ‹©æœ€å¿«çš„å“åº”
- **æˆæœ¬**ï¼šåœ¨ä¿è¯è´¨é‡çš„å‰æä¸‹é€‰æ‹©æœ€ä½³æ€§ä»·æ¯”
- **é…é¢**ï¼šé¿å…å•ä¸ªæä¾›å•†è¿‡è½½

### 2. æ•…éšœè½¬ç§»
å¦‚æœä¸»æä¾›å•†ä¸å¯ç”¨ï¼š
```
ç”¨æˆ·è¯·æ±‚
    â†“
æ£€æŸ¥æä¾›å•† A çŠ¶æ€
    â†“ ï¼ˆå¦‚æœ A ä¸å¯ç”¨ï¼‰
è‡ªåŠ¨åˆ‡æ¢åˆ°æä¾›å•† B
    â†“
è¿”å›ç»“æœ
```

### 3. æ¨¡å‹æ˜ å°„
æˆ‘ä»¬ç»´æŠ¤è¯¦ç»†çš„æ¨¡å‹æ˜ å°„ï¼š
| æ‚¨è¯·æ±‚çš„æ¨¡å‹ | OpenAI | Anthropic | Gemini | AWS Bedrock |
|-------------|--------|-----------|--------|-------------|
| `gpt-4` | âœ… GPT-4 | âŒ | âŒ | âŒ |
| `gpt-3.5-turbo` | âœ… | âŒ | âŒ | âŒ |
| `claude-3-sonnet` | âŒ | âœ… | âŒ | âœ… |
| `gemini-pro` | âŒ | âŒ | âœ… | âŒ |
| `auto` | æ™ºèƒ½é€‰æ‹© |

**æ™ºèƒ½é€‰æ‹©é€»è¾‘**ï¼š
- å¦‚æœè¯·æ±‚ç‰¹å®šæ¨¡å‹ï¼Œä½¿ç”¨è¯¥æ¨¡å‹
- å¦‚æœ `auto` æˆ–é€šç”¨åç§°ï¼ŒåŸºäºå½“å‰çŠ¶æ€é€‰æ‹©æœ€ä½³æ¨¡å‹
- å¦‚æœä¸»æä¾›å•†é…é¢è€—å°½ï¼Œè‡ªåŠ¨åˆ‡æ¢åˆ°å¤‡ç”¨æä¾›å•†

## âš™ï¸ é«˜çº§é…ç½®

### 1. é¦–é€‰æä¾›å•†
é€šè¿‡è¯·æ±‚å¤´æŒ‡å®šé¦–é€‰æä¾›å•†ï¼š
```bash
curl https://api.pipellm.com/v1/chat/completions \
  -H "Authorization: Bearer YOUR_API_KEY" \
  -H "X-Preferred-Provider: anthropic" \
  -d '{"model": "auto", "messages": [...]}'
```

**å¯ç”¨æä¾›å•†**ï¼š
- `openai` - OpenAI
- `anthropic` - Anthropic Claude
- `google` - Google Gemini
- `azure` - Azure OpenAI
- `aws` - AWS Bedrock

### 2. å¼ºåˆ¶æŒ‡å®šæä¾›å•†
ç»•è¿‡æ™ºèƒ½è·¯ç”±ï¼š
```bash
curl https://api.pipellm.com/v1/chat/completions \
  -H "Authorization: Bearer YOUR_API_KEY" \
  -H "X-Force-Provider: openai" \
  -d '{"model": "auto", "messages": [...]}'
```

### 3. ç¦ç”¨æ ¼å¼è½¬æ¢
ç›´æ¥ä½¿ç”¨åŸç”Ÿæ ¼å¼ï¼š
```bash
curl https://api.pipellm.com/v1/chat/completions \
  -H "Authorization: Bearer YOUR_API_KEY" \
  -H "X-Raw-Format: anthropic" \
  -d '{"model": "claude-3-sonnet", "messages": [...]}'
```

## âš¡ æ€§èƒ½ä¼˜åŒ–

### 1. é›¶è½¬æ¢å¼€é”€
æ ¼å¼è½¬æ¢å¼€é”€æœ€å°ï¼š
- è¯·æ±‚è½¬æ¢ï¼š< 1ms
- å“åº”è½¬æ¢ï¼š< 1ms
- æ€»å»¶è¿Ÿå¢åŠ ï¼š< 2ms

### 2. æ™ºèƒ½ç¼“å­˜
è‡ªåŠ¨è·¨æä¾›å•†ç¼“å­˜ï¼š
- ä¸æ ¼å¼æ— å…³çš„è·¨æä¾›å•†ç¼“å­˜
- æ™ºèƒ½ç¼“å­˜é”®ç”Ÿæˆ
- è‡ªåŠ¨ç¼“å­˜åˆ·æ–°

### 3. è¿æ¥å¤ç”¨
- é•¿è¿æ¥
- è¿æ¥æ± ç®¡ç†
- å¹¶å‘è¯·æ±‚ä¼˜åŒ–

## ğŸ› ï¸ å¼€å‘è€…å·¥å…·

### 1. è°ƒè¯•æ¨¡å¼
å¯ç”¨è°ƒè¯•æ¨¡å¼æŸ¥çœ‹è½¬æ¢è¯¦æƒ…ï¼š
```bash
curl https://api.pipellm.com/v1/chat/completions \
  -H "Authorization: Bearer YOUR_API_KEY" \
  -H "X-Debug: true" \
  -d '{"model": "auto", "messages": [...]}'
```

å“åº”åŒ…å«ï¼š
```json
{
  "_debug": {
    "original_request": {...},
    "converted_request": {...},
    "provider": "openai",
    "conversion_time_ms": 1.2,
    "cache_hit": false
  },
  "choices": [...]
}
```

### 2. æ€§èƒ½ç›‘æ§
é€šè¿‡ç®¡ç†ä»ªè¡¨æ¿ç›‘æ§ï¼š
- æä¾›å•†ä½¿ç”¨ç»Ÿè®¡
- è½¬æ¢æ—¶é—´åˆ†æ
- ç¼“å­˜å‘½ä¸­ç‡
- æ•…éšœè½¬ç§»æ¬¡æ•°

## ğŸ“ ä½¿ç”¨æŒ‡å—

### 1. æœ€ä½³å®è·µ
**æ¨è**ï¼š
- ä½¿ç”¨æ ‡å‡† OpenAI æ ¼å¼
- è®©ç½‘å…³è‡ªåŠ¨é€‰æ‹©æä¾›å•†
- é€‚å½“ä½¿ç”¨ç¼“å­˜
- å®ç°é‡è¯•é€»è¾‘

**ä¸æ¨è**ï¼š
- é¢‘ç¹åˆ‡æ¢æä¾›å•†
- ç¦ç”¨æ™ºèƒ½è·¯ç”±ï¼ˆé™¤éå¿…è¦ï¼‰
- å¿½ç•¥é”™è¯¯å¤„ç†

### 2. è¿ç§»æŒ‡å—
**æ­¥éª¤ 1**ï¼šä¿æŒç°æœ‰ä»£ç ä¸å˜
```python
# åŸå§‹ä»£ç 
import openai
openai.api_key = "YOUR_OPENAI_KEY"
openai.api_base = "https://api.openai.com/v1/"

# ä¿®æ”¹ä¸º
openai.api_base = "https://api.pipellm.com/v1/"
openai.api_key = "YOUR_GATEWAY_KEY"
```

**æ­¥éª¤ 2**ï¼šæµ‹è¯•åŸºæœ¬åŠŸèƒ½
```python
response = openai.ChatCompletion.create(
    model="gpt-4",
    messages=[{"role": "user", "content": "test"}]
)
print(response.choices[0].message.content)
```

**æ­¥éª¤ 3**ï¼šé€æ­¥ä¼˜åŒ–
- æ ¹æ®éœ€è¦è°ƒæ•´æ¨¡å‹é€‰æ‹©
- å¯ç”¨æ‰¹é‡è¯·æ±‚
- é…ç½®ç›‘æ§å‘Šè­¦

## ğŸ¤ æ”¯æŒ
å¦‚æœé‡åˆ°æ ¼å¼è½¬æ¢é—®é¢˜ï¼š
1. **å¯ç”¨è°ƒè¯•æ¨¡å¼**è·å–è¯¦ç»†ä¿¡æ¯
2. **æ£€æŸ¥è¯·æ±‚æ—¥å¿—**ç¡®è®¤è½¬æ¢
3. **è”ç³»æ”¯æŒ**æä¾›è°ƒè¯•ä¿¡æ¯

---

**æç¤º**ï¼šå¤§å¤šæ•°æƒ…å†µä¸‹ï¼Œæ‚¨æ— éœ€å…³å¿ƒæ ¼å¼è½¬æ¢ç»†èŠ‚ã€‚æˆ‘ä»¬çš„ç½‘å…³ä¼šè‡ªåŠ¨å¤„ç†ä¸€åˆ‡ï¼