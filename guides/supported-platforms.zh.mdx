---
title: "æ”¯æŒçš„ LLM å¹³å°"
description: "PipeLLM ç½‘å…³æ”¯æŒçš„æ‰€æœ‰ LLM æœåŠ¡æä¾›å•†åŠå…¶åŠŸèƒ½"
i18n: "zh"
---

# æ”¯æŒçš„ LLM å¹³å°

PipeLLM ç½‘å…³æ”¯æŒä¸»æµçš„ LLM æœåŠ¡æä¾›å•†ã€‚**æœ€å¤§ä¼˜åŠ¿**ï¼šä½¿ç”¨å®˜æ–¹ SDKï¼ˆAnthropicã€OpenAIã€Google ç­‰ï¼‰ï¼Œåªéœ€æ›´æ”¹ baseURL å³å¯é€æ˜åœ°è®¿é—®ä»»ä½•å¹³å°ã€‚

**æ— éœ€å­¦ä¹ æ–° APIï¼Œé›¶ä»£ç æ›´æ”¹ï¼**

**å®Œæ•´æ¨¡å‹åˆ—è¡¨**ï¼š[https://www.pipellm.com/models](https://www.pipellm.com/models)

## ğŸ¤– OpenAI ç”Ÿæ€ç³»ç»Ÿ

### OpenAI å®˜æ–¹
**çŠ¶æ€**ï¼šâœ… å®Œå…¨æ”¯æŒ

**ä½¿ç”¨æ–¹æ³•**ï¼šä½¿ç”¨ OpenAI å®˜æ–¹ SDK
```python
import openai
client = openai.OpenAI(
    api_key="your-pipellm-key",
    base_url="https://api.pipellm.com/v1"  # æŒ‡å‘æˆ‘ä»¬çš„ç½‘å…³
)

response = client.chat.completions.create(
    model="gpt-4",
    messages=[{"role": "user", "content": "Hello"}]
)
```

**æ”¯æŒçš„æ¨¡å‹**ï¼š
- **GPT-4 ç³»åˆ—**ï¼š`gpt-4`ã€`gpt-4-turbo`ã€`gpt-4o`ã€`gpt-4o-mini`
- **GPT-3.5 ç³»åˆ—**ï¼š`gpt-3.5-turbo`ã€`gpt-3.5-turbo-16k`
- **åµŒå…¥æ¨¡å‹**ï¼š`text-embedding-ada-002`ã€`text-embedding-3-small`ã€`text-embedding-3-large`
- **è¯­éŸ³**ï¼š`whisper-1`
- **å›¾åƒ**ï¼š`dall-e-3`ã€`dall-e-2`

### Azure OpenAI
**çŠ¶æ€**ï¼šâœ… å®Œå…¨æ”¯æŒ

**ä½¿ç”¨æ–¹æ³•**ï¼šä½¿ç”¨ OpenAI SDKï¼Œé€æ˜è°ƒç”¨ Azure æœåŠ¡
```python
import openai
client = openai.OpenAI(
    api_key="your-pipellm-key",
    base_url="https://api.pipellm.com/v1"  # æŒ‡å‘æˆ‘ä»¬çš„ç½‘å…³
)

response = client.chat.completions.create(
    model="gpt-4",
    messages=[{"role": "user", "content": "Hello"}]
)
```

**æ”¯æŒçš„æ¨¡å‹**ï¼š
- **GPT-4 ç³»åˆ—**ï¼š`gpt-4`ã€`gpt-4-32k`ã€`gpt-4-turbo`ã€`gpt-4o`
- **GPT-3.5 ç³»åˆ—**ï¼š`gpt-35-turbo`ã€`gpt-35-turbo-16k`
- **åµŒå…¥æ¨¡å‹**ï¼š`text-embedding-ada-002`

## ğŸ¦™ Anthropic Claude
**çŠ¶æ€**ï¼šâœ… å®Œå…¨æ”¯æŒ

**ä½¿ç”¨æ–¹æ³•**ï¼šä½¿ç”¨ Anthropic å®˜æ–¹ SDK
```python
from anthropic import Anthropic
client = Anthropic(
    api_key="your-pipellm-key",
    base_url="https://api.pipellm.com/v1"  # æŒ‡å‘æˆ‘ä»¬çš„ç½‘å…³
)

response = client.messages.create(
    model="claude-3-sonnet",
    messages=[{"role": "user", "content": "Hello"}]
)
```

**æ”¯æŒçš„æ¨¡å‹**ï¼š
- **Claude 3 ç³»åˆ—**ï¼š
  - `claude-3-haiku` - å¿«é€Ÿã€ç»æµ
  - `claude-3-sonnet` - å¹³è¡¡æ€§èƒ½
  - `claude-3-opus` - æœ€é«˜è´¨é‡
  - `claude-3-5-sonnet` - æœ€æ–°ç‰ˆæœ¬

**Claude ç‰¹æ€§**ï¼š
- é•¿ä¸Šä¸‹æ–‡å¤„ç†ï¼ˆæ”¯æŒ 200K tokensï¼‰
- å‡ºè‰²çš„æ¨ç†å’Œåˆ†æèƒ½åŠ›
- å¼ºå¤§çš„æŒ‡ä»¤éµå¾ª
- å·¥å…·ä½¿ç”¨æ”¯æŒ

**é€æ˜è·¨å¹³å°è°ƒç”¨**ï¼š
| æ‚¨çš„ SDK | å®é™…å¹³å° | è¯´æ˜ |
|---------|---------|------|
| Anthropic SDK | AWS Bedrock | è‡ªåŠ¨è½¬æ¢ä¸º Bedrock åè®® |
| Anthropic SDK | Google Vertex | è‡ªåŠ¨è½¬æ¢ä¸º Vertex åè®® |
| Anthropic SDK | Azure | è‡ªåŠ¨è½¬æ¢ä¸º Azure åè®® |
| Anthropic SDK | Anthropic å®˜æ–¹ | ç›´æ¥è°ƒç”¨ |

## ğŸ¤– Google Gemini
**çŠ¶æ€**ï¼šâœ… å®Œå…¨æ”¯æŒ

**ä½¿ç”¨æ–¹æ³•**ï¼šä½¿ç”¨ Google çš„åŸç”Ÿåº“æˆ–æ ‡å‡† API
```python
import requests

headers = {
    "Authorization": f"Bearer your-pipellm-key",
    "Content-Type": "application/json"
}

data = {
    "model": "gemini-pro",
    "contents": [{"role": "user", "parts": [{"text": "Hello"}]}]
}

response = requests.post(
    "https://api.pipellm.com/v1/chat/completions",
    headers=headers,
    json=data
)
```

**æ”¯æŒçš„æ¨¡å‹**ï¼š
- `gemini-pro` - é€šç”¨æ¨¡å‹
- `gemini-pro-vision` - å¤šæ¨¡æ€æ¨¡å‹
- `gemini-ultra` - é«˜çº§æ¨¡å‹ï¼ˆå¦‚æœå¯ç”¨ï¼‰

**Gemini ç‰¹æ€§**ï¼š
- å¤šæ¨¡æ€èƒ½åŠ›ï¼ˆæ–‡æœ¬ + å›¾åƒï¼‰
- ä»£ç ç”Ÿæˆä¼˜åŒ–
- å¿«é€Ÿå“åº”
- Google ç”Ÿæ€ç³»ç»Ÿé›†æˆ

## â˜ï¸ AWS Bedrock
**çŠ¶æ€**ï¼šâœ… å®Œå…¨æ”¯æŒ

**ä½¿ç”¨æ–¹æ³•**ï¼šä½¿ç”¨åŸç”Ÿ SDK è°ƒç”¨ Bedrock æœåŠ¡
```python
# ä½¿ç”¨ Anthropic SDK è°ƒç”¨ Bedrock ä¸Šçš„ Claude
from anthropic import Anthropic

client = Anthropic(
    api_key="your-pipellm-key",
    base_url="https://api.pipellm.com/v1"  # æŒ‡å‘æˆ‘ä»¬çš„ç½‘å…³
)

response = client.messages.create(
    model="anthropic.claude-3-sonnet-20240229-v1:0",
    messages=[{"role": "user", "content": "Hello"}]
)

# ä½¿ç”¨ OpenAI SDK è°ƒç”¨ Bedrock ä¸Šçš„ Llama 3
import openai
client = openai.OpenAI(
    api_key="your-pipellm-key",
    base_url="https://api.pipellm.com/v1"
)

response = client.chat.completions.create(
    model="meta.llama3-70b-instruct-v1:0",
    messages=[{"role": "user", "content": "Write a React component"}]
)
```

**æ”¯æŒçš„æ¨¡å‹**ï¼š
- **Anthropic**ï¼š`claude-3-haiku`ã€`claude-3-sonnet`ã€`claude-3-opus`
- **Amazon Titan**ï¼š`amazon.titan-text-express-v1`ã€`amazon.titan-text-lite-v1`
- **AI21 Labs**ï¼š`ai21.j2-mid`ã€`ai21.j2-ultra`
- **Cohere**ï¼š`cohere.command-text-v14`ã€`cohere.command-light-text-v14`
- **Meta**ï¼š`meta.llama3-8b-instruct`ã€`meta.llama3-70b-instruct`ã€`meta.llama3-1-8b-instruct`ã€`meta.llama3-1-70b-instruct`ã€`meta.llama3-2-11b-vision`ã€`meta.llama3-2-90b-vision`
- **Mistral**ï¼š`mistral.mistral-7b-instruct`ã€`mistral.mixtral-8x7b-instruct`ã€`mistral.mistral-large-latest`ã€`mistral.mistral-small-latest`
- **Stability AI**ï¼š`stability.stable-diffusion-xl-v1-0`

**Bedrock ä¼˜åŠ¿**ï¼š
- AWS åŸç”Ÿé›†æˆ
- ä¼ä¸šçº§å®‰å…¨æ€§
- å¯æ‰©å±•æ€§
- æŒ‰éœ€ä»˜è´¹

## ğŸŒ å…¶ä»–äº‘å¹³å°

### Google Vertex AI
**çŠ¶æ€**ï¼šâœ… å®Œå…¨æ”¯æŒ

### Fireworks AI
**çŠ¶æ€**ï¼šâœ… å®Œå…¨æ”¯æŒ

**æ”¯æŒçš„æ¨¡å‹**ï¼š
- `accounts/fireworks/models/firefunction-v2`
- `accounts/fireworks/models/llama-v3p1-405b`
- `accounts/fireworks/models/llama-v3p1-70b`
- `accounts/fireworks/models/llama-v3p1-8b`
- `accounts/stabilityai/models/stable-diffusion-xl-1024-v1-0`
- å…¶ä»– Fireworks æ¨¡å‹

### Together AI
**çŠ¶æ€**ï¼šâœ… å®Œå…¨æ”¯æŒ

**æ”¯æŒçš„æ¨¡å‹**ï¼š
- `Nous-Hermes-2-Mixtral-8x7B-DPO`
- `Llama-3-8b-SFT`
- `CodeLlama-34b`
- `WizardLM-2-8x22b`
- å…¶ä»– Together AI æ¨¡å‹

### Groq
**çŠ¶æ€**ï¼šâœ… å®Œå…¨æ”¯æŒ

**æ”¯æŒçš„æ¨¡å‹**ï¼š
- `llama3-8b-8192`
- `llama3-70b-8192`
- `mixtral-8x7b-32768`
- `gemma-7b-it`
- `gemma2-9b-it`
- `llama-3-3-70b-versatile`
- `llama-3-3-8b-instant`

**ä¼˜åŠ¿**ï¼š
- è¶…å¿«æ¨ç†
- ä½å»¶è¿Ÿ
- å®æ—¶åº”ç”¨ä¼˜åŒ–

### Replicate
**çŠ¶æ€**ï¼šâœ… å®Œå…¨æ”¯æŒ

**æ”¯æŒçš„åŠŸèƒ½**ï¼š
- å›¾åƒç”Ÿæˆ
- è§†é¢‘ç”Ÿæˆ
- éŸ³é¢‘å¤„ç†
- è‡ªå®šä¹‰æ¨¡å‹éƒ¨ç½²

### OpenRouter
**çŠ¶æ€**ï¼šâœ… å®Œå…¨æ”¯æŒ

**ç‰¹æ€§**ï¼š
- èšåˆå¤šä¸ªæä¾›å•†
- ç»Ÿä¸€è®¡è´¹
- ç®€åŒ–è®¿é—®

## ğŸ¨ åª’ä½“å¤„ç†å¹³å°

### Stability AI
**çŠ¶æ€**ï¼šâœ… å®Œå…¨æ”¯æŒ

**æ”¯æŒçš„æ¨¡å‹**ï¼š
- `stable-diffusion-xl-1024-v1-0`
- `stable-diffusion-3`
- `stable-cascade`
- `stable-video-diffusion`

### Ideogram
**çŠ¶æ€**ï¼šâœ… å®Œå…¨æ”¯æŒ

**ç‰¹æ€§**ï¼š
- åˆ›æ„å›¾åƒç”Ÿæˆ
- æ–‡æœ¬æ¸²æŸ“ä¼˜åŒ–
- è‰ºæœ¯é£æ ¼

### Luma Labs
**çŠ¶æ€**ï¼šâœ… å®Œå…¨æ”¯æŒ

**æ”¯æŒçš„åŠŸèƒ½**ï¼š
- 3D æ¨¡å‹ç”Ÿæˆ
- å›¾åƒåˆ° 3D è½¬æ¢
- è§†é¢‘å¤„ç†

## ğŸ“Š å¹³å°å¯¹æ¯”

| ç‰¹æ€§ | OpenAI | Anthropic | Gemini | AWS Bedrock | Azure |
|------|--------|-----------|--------|-------------|-------|
| **æœ€å¤§ä¸Šä¸‹æ–‡** | 128K | 200K | 32K | 200K | 128K |
| **å¤šæ¨¡æ€** | âœ… | âŒ | âœ… | éƒ¨åˆ† | éƒ¨åˆ† |
| **ä»£ç èƒ½åŠ›** | â­â­â­â­â­ | â­â­â­â­ | â­â­â­â­ | â­â­â­ | â­â­â­â­ |
| **æ¨ç†** | â­â­â­â­ | â­â­â­â­â­ | â­â­â­â­ | â­â­â­â­ | â­â­â­â­ |
| **é€Ÿåº¦** | å¿«é€Ÿ | éå¸¸å¿«é€Ÿ | éå¸¸å¿«é€Ÿ | å¿«é€Ÿ | å¿«é€Ÿ |
| **ä»·æ ¼** | é«˜ | ä¸­ç­‰ | ä½ | ä¸­ç­‰ | ä¸­ç­‰ |
| **ä¼ä¸šçº§** | âœ… | âœ… | âœ… | âœ… | âœ… |

## ğŸš€ å¦‚ä½•é€‰æ‹©åˆé€‚çš„å¹³å°

### 1. æŒ‰ç”¨ä¾‹
**ä»£ç ç”Ÿæˆ**ï¼š
- æœ€ä½³ï¼šOpenAI GPT-4oã€Claude 3
- ç‰¹æ€§ï¼šé«˜å‡†ç¡®æ€§ã€å¤šè¯­è¨€æ”¯æŒ

**é•¿æ–‡æ¡£å¤„ç†**ï¼š
- æœ€ä½³ï¼šClaude 3ï¼ˆ200K ä¸Šä¸‹æ–‡ï¼‰
- ç‰¹æ€§ï¼šå¯å¤„ç†æ•´æœ¬ä¹¦æˆ–ä»£ç åº“

**åˆ›æ„å†™ä½œ**ï¼š
- æœ€ä½³ï¼šOpenAI GPT-4oã€Gemini Pro
- ç‰¹æ€§ï¼šé«˜åˆ›æ„æ€§ã€å¤šæ ·åŒ–é£æ ¼

**ä¼ä¸šåº”ç”¨**ï¼š
- æœ€ä½³ï¼šAzure OpenAIã€AWS Bedrock
- ç‰¹æ€§ï¼šä¼ä¸šçº§å®‰å…¨ã€æ•°æ®ä¿è¯

**æˆæœ¬æ•æ„Ÿ**ï¼š
- æœ€ä½³ï¼šGemini Proã€Llama 3
- ç‰¹æ€§ï¼šé«˜æ€§ä»·æ¯”

### 2. æŒ‰æŠ€æœ¯è¦æ±‚
**å¤šæ¨¡æ€éœ€æ±‚**ï¼š
- OpenAI GPT-4o
- Google Gemini Pro Vision
- AWS Titan Multimodal

**é•¿ä¸Šä¸‹æ–‡**ï¼š
- Anthropic Claude 3ï¼ˆ200Kï¼‰
- OpenAI GPT-4oï¼ˆ128Kï¼‰
- AWS Claude 3ï¼ˆ200Kï¼‰

**å¿«é€Ÿå“åº”**ï¼š
- Groqï¼ˆç¡¬ä»¶åŠ é€Ÿï¼‰
- OpenAIï¼ˆä¼˜åŒ–ç½‘ç»œï¼‰
- Anthropicï¼ˆå¿«é€Ÿæ¨¡å‹ï¼‰

### 3. ä½¿ç”¨ PipeLLM ç½‘å…³çš„ä¼˜åŠ¿
**æ— éœ€æ‰‹åŠ¨é€‰æ‹©**ï¼š
```bash
# ç½‘å…³è‡ªåŠ¨é€‰æ‹©
curl https://api.pipellm.com/v1/chat/completions \
  -H "Authorization: Bearer YOUR_API_KEY" \
  -d '{"model": "auto", "messages": [...]}'
```

**æ™ºèƒ½è·¯ç”±**ï¼š
- åŸºäºè´Ÿè½½è‡ªåŠ¨é€‰æ‹©
- åŸºäºæ¨¡å‹å¯ç”¨æ€§è·¯ç”±
- åŸºäºæˆæœ¬ä¼˜åŒ–

**æ•…éšœè½¬ç§»**ï¼š
- æä¾›å•†ä¸å¯ç”¨æ—¶è‡ªåŠ¨åˆ‡æ¢
- ç¡®ä¿æœåŠ¡è¿ç»­æ€§
- å‡å°‘åœæœºé£é™©

## ğŸ› ï¸ é«˜çº§é…ç½®

### 1. æŒ‡å®šæä¾›å•†åå¥½
```bash
curl https://api.pipellm.com/v1/chat/completions \
  -H "Authorization: Bearer YOUR_API_KEY" \
  -H "X-Preferred-Provider: openai" \
  -d '{"model": "auto", "messages": [...]}'
```

### 2. å¼ºåˆ¶æŒ‡å®šæä¾›å•†
```bash
curl https://api.pipellm.com/v1/chat/completions \
  -H "Authorization: Bearer YOUR_API_KEY" \
  -H "X-Force-Provider: anthropic" \
  -d '{"model": "auto", "messages": [...]}'
```

### 3. æ¨¡å‹åˆ«å
```json
{
  "model": "best",        // æœ€ä½³è´¨é‡
  "model": "fast",        // æœ€å¿«é€Ÿåº¦
  "model": "cheap",       // æœ€ç»æµ
  "model": "balanced"     // å¹³è¡¡æ€§èƒ½
}
```

### 4. åŒºåŸŸé€‰æ‹©
```bash
curl https://api.pipellm.com/v1/chat/completions \
  -H "Authorization: Bearer YOUR_API_KEY" \
  -H "X-Region: us-east-1" \
  -d '{"model": "auto", "messages": [...]}'
```

## ğŸ“ˆ æ€§èƒ½ç›‘æ§
é€šè¿‡ç®¡ç†ä»ªè¡¨æ¿ç›‘æ§ï¼š
- æä¾›å•†æˆåŠŸç‡å¯¹æ¯”
- å¹³å‡å“åº”æ—¶é—´
- æˆæœ¬åˆ†æ
- æ¨¡å‹ä½¿ç”¨ç»Ÿè®¡

## ğŸ¤ æ”¯æŒ
å¦‚æœéœ€è¦å¹³å°æ”¯æŒæˆ–é‡åˆ°é—®é¢˜ï¼š
1. **æŸ¥çœ‹æ–‡æ¡£**ï¼šè®¿é—®æä¾›å•†çš„å®˜æ–¹æ–‡æ¡£
2. **å¯ç”¨è°ƒè¯•æ¨¡å¼**ï¼šä½¿ç”¨ `X-Debug: true` æŸ¥çœ‹è¯¦æƒ…
3. **è”ç³»æ”¯æŒ**ï¼šå‘é€é‚®ä»¶è‡³ support@pipellm.com

---

**æç¤º**ï¼šPipeLLM ç½‘å…³æŒç»­æ·»åŠ å¯¹æ–°å¹³å°å’Œæ¨¡å‹çš„æ”¯æŒã€‚è¯·å…³æ³¨æ›´æ–°ï¼