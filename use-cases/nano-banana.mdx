---
title: "Nano Banana Image Generation"
description: "Generate and edit images with Gemini Nano Banana multimodal models"
i18n: "en"
---

For authentication, see [Overview](/api-reference/gemini/overview).

## What is Nano Banana

Nano Banana is Gemini's **multimodal image generation capability**, using the same `generateContent` endpoint as text models.

| Model | Model ID | Features |
|-------|----------|----------|
| **Nano Banana** | `gemini-2.5-flash-image` | Speed optimized for high-volume tasks |
| **Nano Banana Pro** | `gemini-3-pro-image-preview` | Professional production, advanced reasoning, high-fidelity text rendering, up to 4K resolution |

## Endpoints

Same as text models:

| Type | Endpoint |
|------|----------|
| Non-Streaming | `POST /v1beta/models/{model}:generateContent` |
| Streaming | `POST /v1beta/models/{model}:streamGenerateContent` |

## Text to Image

<Tabs>
  <Tab title="cURL">
```bash
curl -s -X POST \
  "https://api.pipellm.com/v1beta/models/gemini-2.5-flash-image:generateContent" \
  -H "x-goog-api-key: $PIPELLM_API_KEY" \
  -H "Content-Type: application/json" \
  -d @- << 'EOF'
{
  "contents": [{
    "parts": [
      {"text": "Create a picture of a nano banana dish in a fancy restaurant with a Gemini theme"}
    ]
  }]
}
EOF
```
  </Tab>
  <Tab title="Python">
```python
from google import genai
from PIL import Image

client = genai.Client(
  api_key=os.getenv('PIPELLM_API_KEY'),
  http_options={'base_url': 'https://api.pipellm.com'}
)

response = client.models.generate_content(
  model="gemini-2.5-flash-image",
  contents=["Create a picture of a nano banana dish in a fancy restaurant with a Gemini theme"],
)

for part in response.parts:
  if part.text is not None:
    print(part.text)
  elif part.inline_data is not None:
    image = part.as_image()
    image.save("generated_image.png")
```
  </Tab>
  <Tab title="Node.js">
```javascript
import { GoogleGenAI } from "@google/genai";
import * as fs from "node:fs";

const ai = new GoogleGenAI({
  apiKey: process.env.PIPELLM_API_KEY,
  httpOptions: { baseUrl: 'https://api.pipellm.com' }
});

const response = await ai.models.generateContent({
  model: "gemini-2.5-flash-image",
  contents: "Create a picture of a nano banana dish in a fancy restaurant with a Gemini theme",
});

for (const part of response.candidates[0].content.parts) {
  if (part.text) {
    console.log(part.text);
  } else if (part.inlineData) {
    const buffer = Buffer.from(part.inlineData.data, "base64");
    fs.writeFileSync("generated_image.png", buffer);
  }
}
```
  </Tab>
</Tabs>

## Image to Image (with Reference)

Upload a reference image and generate a new one with text prompts:

<Tabs>
  <Tab title="cURL">
```bash
IMG_BASE64=$(base64 -w0 /path/to/cat_image.jpeg)

curl -s -X POST \
  "https://api.pipellm.com/v1beta/models/gemini-2.5-flash-image:generateContent" \
  -H "x-goog-api-key: $PIPELLM_API_KEY" \
  -H "Content-Type: application/json" \
  -d @- << EOF
{
  "contents": [{
    "parts": [
      {"text": "Create a picture of my cat eating a nano-banana in a fancy restaurant under the Gemini constellation"},
      {"inline_data": {"mime_type": "image/jpeg", "data": "$IMG_BASE64"}}
    ]
  }]
}
EOF
```
  </Tab>
  <Tab title="Python">
```python
from google import genai
from PIL import Image

client = genai.Client(
  api_key=os.getenv('PIPELLM_API_KEY'),
  http_options={'base_url': 'https://api.pipellm.com'}
)

image = Image.open('/path/to/cat_image.png')

response = client.models.generate_content(
  model="gemini-2.5-flash-image",
  contents=[
    "Create a picture of my cat eating a nano-banana in a fancy restaurant under the Gemini constellation",
    image
  ],
)

for part in response.parts:
  if part.text is not None:
    print(part.text)
  elif part.inline_data is not None:
    image = part.as_image()
    image.save("edited_image.png")
```
  </Tab>
  <Tab title="Node.js">
```javascript
import { GoogleGenAI } from "@google/genai";
import * as fs from "node:fs";

const ai = new GoogleGenAI({
  apiKey: process.env.PIPELLM_API_KEY,
  httpOptions: { baseUrl: 'https://api.pipellm.com' }
});

const imageData = fs.readFileSync("cat_image.png");
const base64Image = imageData.toString("base64");

const response = await ai.models.generateContent({
  model: "gemini-2.5-flash-image",
  contents: [
    { text: "Create a picture of my cat eating a nano-banana in a fancy restaurant under the Gemini constellation" },
    { inlineData: { mimeType: "image/png", data: base64Image } }
  ],
});

for (const part of response.candidates[0].content.parts) {
  if (part.text) {
    console.log(part.text);
  } else if (part.inlineData) {
    const buffer = Buffer.from(part.inlineData.data, "base64");
    fs.writeFileSync("edited_image.png", buffer);
  }
}
```
  </Tab>
</Tabs>

## Response Format

Image generation responses are multimodal, containing text and base64-encoded image data:

```json
{
  "candidates": [{
    "content": {
      "parts": [
        { "text": "Here is your generated image..." },
        {
          "inlineData": {
            "mimeType": "image/png",
            "data": "<BASE64_IMAGE_DATA>"
          }
        }
      ]
    }
  }]
}
```

## More Features

<Card title="Nano Banana Documentation" icon="book" href="https://ai.google.dev/gemini-api/docs/image-generation">
  Supports multi-turn editing, 4K resolution, multi-image composition, and more
</Card>
