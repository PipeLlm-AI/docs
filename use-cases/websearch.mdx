---
title: "Web Search"
description: "Search the web in real-time through PipeLLM Gateway"
i18n: "en"
---

## Overview

PipeLLM WebSearch provides real-time web search capability through the Gateway, with per-request billing. Perfect for RAG (Retrieval-Augmented Generation) and building AI agents with web access.

## Endpoint

| Method | Endpoint                                      |
| ------ | --------------------------------------------- |
| GET    | `https://api.pipellm.com/v1/websearch/search` |

## Authentication

Use your PipeLLM API key in the `Authorization` header:

```
Authorization: Bearer YOUR_PIPELLM_API_KEY
```

## Request

| Parameter | Type   | Required | Description  |
| --------- | ------ | -------- | ------------ |
| `q`       | string | Yes      | Search query |

### Example Request

<Tabs>
  <Tab title="cURL">
```bash
curl -X GET "https://api.pipellm.com/v1/websearch/search?q=latest+AI+news" \
  -H "Authorization: Bearer $PIPELLM_API_KEY"
```
  </Tab>
  <Tab title="Python">
```python
import requests
import os

response = requests.get(
"https://api.pipellm.com/v1/websearch/search",
params={"q": "latest AI news"},
headers={"Authorization": f"Bearer {os.getenv('PIPELLM_API_KEY')}"}
)

data = response.json()
for result in data.get("data", {}).get("organic", []):
print(f"- {result['title']}: {result['link']}")

````
  </Tab>
  <Tab title="Node.js">
```javascript
const response = await fetch(
  "https://api.pipellm.com/v1/websearch/search?q=latest+AI+news",
  {
    headers: {
      Authorization: `Bearer ${process.env.PIPELLM_API_KEY}`,
    },
  }
);

const data = await response.json();
data.data.organic.forEach((result) => {
  console.log(`- ${result.title}: ${result.link}`);
});
````

  </Tab>
</Tabs>

## Response Format

```json
{
  "code": 200,
  "message": "ok",
  "data": {
    "searchParameters": {
      "q": "latest AI news",
      "gl": "us",
      "hl": "en"
    },
    "answerBox": {
      "title": "Featured Snippet Title",
      "snippet": "Quick answer from Google's featured snippet...",
      "link": "https://example.com/source"
    },
    "organic": [
      {
        "title": "Result Title",
        "link": "https://example.com/page",
        "snippet": "Page description or excerpt..."
      }
    ]
  }
}
```

### Response Fields

| Field                    | Type    | Description                              |
| ------------------------ | ------- | ---------------------------------------- |
| `code`                   | integer | `0` for success, non-zero for errors     |
| `message`                | string  | Status message                           |
| `data.searchParameters`  | object  | Search parameters used                   |
| `data.answerBox`         | object  | Google's featured snippet (if available) |
| `data.organic`           | array   | List of organic search results           |
| `data.organic[].title`   | string  | Page title                               |
| `data.organic[].link`    | string  | Page URL                                 |
| `data.organic[].snippet` | string  | Page description                         |

### Error Response

```json
{
  "code": 400,
  "message": "Bad Request, missing query parameter"
}
```

## Pricing

| Item        | Price |
| ----------- | ----- |
| Per Request | $0.05 |

<Note>Billing is per successful request. Failed requests are not charged.</Note>

## Use Cases

### RAG Context Enhancement

Use WebSearch to provide real-time context for your LLM:

```python
import requests
import os
from openai import OpenAI

# Step 1: Search the web
search_response = requests.get(
    "https://api.pipellm.com/v1/websearch/search",
    params={"q": "OpenAI o3 model capabilities"},
    headers={"Authorization": f"Bearer {os.getenv('PIPELLM_API_KEY')}"}
)
search_data = search_response.json()

# Step 2: Extract context
context = "\n".join([
    f"[{r['title']}]({r['link']}): {r['snippet']}"
    for r in search_data.get("data", {}).get("organic", [])[:5]
])

# Step 3: Use with LLM
client = OpenAI(
    api_key=os.getenv("PIPELLM_API_KEY"),
    base_url="https://api.pipellm.com/v1"
)

response = client.chat.completions.create(
    model="gpt-4o",
    messages=[
        {"role": "system", "content": f"Use this context:\n{context}"},
        {"role": "user", "content": "What are the key features of OpenAI o3?"}
    ]
)

print(response.choices[0].message.content)
```

## Rate Limits

WebSearch requests share your account's rate limit. If you receive a `503 Service Unavailable` response with `Retry-After` header, please wait and retry.
